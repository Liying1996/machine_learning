
### [1. 线性回归 (Linear Regression)](https://github.com/Liying1996/machine_learining/blob/master/Linear_regression.ipynb)
  
1). 简单线性回归概述、损失函数的推导过程；  
2). 自己实现简单线性回归及简化（向量化）；  
3). 衡量线性回归的常用指标（MSE/RMSE/MAE）以及$R^2$；  
4). 多元线性回归概述；  
5). 自己实现多元线性回归；  
5). sklearn中的多元线性回归。  


---

### [2. 多项式回归 (Polynomial Regression)](https://github.com/Liying1996/machine_learining/blob/master/Polynomial_Regression.ipynb)
1). 多项式回归的概念；  
2). sklearn中的多项式回归；  
3). 理解过拟合与欠拟合，使用交叉验证；  
4). 偏差方差平衡；  
5). 模型泛化与岭回归(Ridge Regression)；  
6). Lasso正则化。  


---

### [3. 逻辑回归 (Logistic Regression)](https://github.com/Liying1996/machine_learining/blob/master/Logistic_regression.ipynb)
1). 逻辑回归概述；  
2). 逻辑回归的损失函数推导及求解；  
3). 自己实现逻辑回归；  
4). sklearn实现二分类逻辑回归；  
5). 决策边界；  
6). 在逻辑回归中使用多项式特征；  
7). 多分类问题(OvR/OvO)。  

---

### [4. K最近邻 (K-Nearest Neighbor)](https://github.com/Liying1996/machine_learining/blob/master/KNN.ipynb)
1). KNN的概述和计算；    
2). 自己实现KNN算法；  
3). sklearn中的实现；  
4). 网格化搜索确定KNN的超参数；  
5). 数据归一化(Feature Scaling)；  
6). KNN的局限性。  
【以上在KNN.ipynb】

---

### [5. 决策树 (Decision Tree)](https://github.com/Liying1996/machine_learining/blob/master/Decision_tree.ipynb)
1). 决策树的概念；  
2). 什么是信息熵；  
3). 什么是信息增益；  
4). 基尼(Gini)系数及计算方法；  
5). 调整KNN的参数；  
6). 决策树的局限性。  

---

### [6. 支撑向量机 (Support Vector Machine)](https://github.com/Liying1996/machine_learining/blob/master/SVM.ipynb)
1). SVM的概念及公式推导；  
2). Soft Margin SVM的理解和推导；  
3). Soft Margin SVM在sklearn中的实现；  
4). 在SVM中使用多项式特征；  
5). 多项式核函数；  
6). 高斯核函数(RBF)；  

---

### [7. 集成学习 (Ensemble Learning)](https://github.com/Liying1996/machine_learining/blob/master/Ensemble_Learning.ipynb)
1). 集成学习的概念；  
2). sklearn中的集成学习(Hard/Soft)；  
3). Bagging与Pasting的理解；  
4). 随机森林与Extra Trees；  
5). 集成学习解决回归问题；  
6). Ada Boosting 与 Gradient Boosting；  
7). Stacking的概念。  

---

### [8. 主成分分析 (Principal Component Analysis)](https://github.com/Liying1996/machine_learining/blob/master/PCA.ipynb)
1). 主成分分析的概念；  
2). 梯度上升法求解；  
3). 自己实现主成分分析；  
4). sklearn中的PCA；  
5). 使用手写数据集；  
6). PCA降噪。  

---

### [9. 梯度下降法 (Gradient Decent)](https://github.com/Liying1996/machine_learining/blob/master/Gradient_descent.ipynb)
1). 梯度下降法的概念；  
2). 梯度下降法的实现；  
3). 线性回归中的梯度下降法；  
4). 向量化与数据标准化；  
5). 梯度下降法的优势；  
6). 随机梯度下降法(stochastic gradient decent)。  

---

### [10. 模型的评价标准](https://github.com/Liying1996/machine_learining/blob/master/Evaluation_metrics.ipynb)
1). 准确度的陷阱；  
2). 混淆矩阵；  
3). 精准率和召回率；   
4). F1 score；     
5). PR曲线；  
6). ROC曲线。

---

### [11. Numpy基础](https://github.com/Liying1996/machine_learining/blob/master/Basic_numpy.ipynb)
1). 创建numpy数组/矩阵；  
2). 合并；  
3). 分割；  
4). 矩阵运算；  
5). 聚合运算；  
6). 索引。  

---
